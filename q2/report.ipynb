{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 PatchSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](plots_temp/1.png)`\n",
    "\n",
    "- This is without augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 and 2.2.3\n",
    "\n",
    "- Hyperparameter exploration: with a bottle neck of 50k dataset we augument the dataset using Flip and pad_followed_by_crop to help generalize training more for differnt parts of images at different angles and stuff.\n",
    "\n",
    "![](plots_temp/2.png)\n",
    "\n",
    "- Here it is still 4 > 2 > 8  for patch size.\n",
    "\n",
    "- This is with color jittering with bad results\n",
    "\n",
    "- From this we can see that 2d-learned > 1d_learned because images and ones and sinusoidal performance is not that good for smaller models, sinusoidal is better for larger models(in the diagram 768 hidden dimension)\n",
    "- color jittering works very bad compared to rotations and crops. \n",
    "- The below two are for color jittering and flip + crop\n",
    "- larger layers generalized better. note this is with data augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below are initial layer heads\n",
    "\n",
    "![](plots_2.4.2/layer_0_attn-head0.png)\n",
    "![](plots_2.4.2/layer_0_attn-head1.png)\n",
    "![](plots_2.4.2/layer_0_attn-head2.png)\n",
    "![](plots_2.4.2/layer_0_attn-head3.png)\n",
    "\n",
    "- This is 4th layer\n",
    "\n",
    "\n",
    "![](plots_2.4.2/layer_4_attn-head0.png)\n",
    "![](plots_2.4.2/layer_4_attn-head1.png)\n",
    "![](plots_2.4.2/layer_4_attn-head2.png)\n",
    "![](plots_2.4.2/layer_4_attn-head3.png)\n",
    "\n",
    "- This is last layer\n",
    "\n",
    "![](plots_2.4.2/layer_7_attn-head0.png)\n",
    "![](plots_2.4.2/layer_7_attn-head1.png)\n",
    "![](plots_2.4.2/layer_7_attn-head2.png)\n",
    "![](plots_2.4.2/layer_7_attn-head3.png)\n",
    "\n",
    "We can see the gradual increase in noise after each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3 rollout\n",
    "\n",
    "![](plots_2.4.3/attention_rollout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.4 pos_embeddings\n",
    "![](plots_2.4.4/pos_embed_similarity.png)\n",
    "![](plots_2.4.4/pos_embed_grid_similarity.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
